[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "å…³äºæˆ‘",
    "section": "",
    "text": "æ¬¢è¿æ¥åˆ°æˆ‘çš„ç½‘ç«™ï¼\nå¤§å®¶å¥½ï¼æˆ‘æ˜¯å¼ é¢ï¼Œè¿™æ˜¯æˆ‘ç”¨ Quarto åˆ›å»ºçš„ä¸ªäººå­¦ä¹ ç½‘ç«™ã€‚\n\nå…´è¶£çˆ±å¥½:çˆ±å¥½æ‰“ç¯®çƒï¼Œç¾½æ¯›çƒï¼Œæ‘„å½± ã€‚\nç›®æ ‡:æˆä¸ºæ›´ä¼˜ç§€çš„äºº ã€‚\n\næ„Ÿè°¢æ‚¨è®¿é—®æˆ‘çš„ç½‘ç«™ï¼ğŸ˜Š"
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\ndf.info()\næ¸©åº¦å¼‚å¸¸æ˜¯æŒ‡ç›¸å¯¹äºæŸä¸ªå‚è€ƒæ—¶æœŸçš„å¹³å‡æ¸©åº¦çš„åç¦»æƒ…å†µã€‚å®ƒæ˜¯ä¸€ç§è¡¡é‡å½“å‰æ¸©åº¦ä¸é•¿æœŸå¹³å‡æ¸©åº¦å·®å€¼çš„æ–¹å¼ï¼Œé‡ç‚¹åœ¨äºä½“ç°æ¸©åº¦çš„å˜åŒ–æƒ…å†µï¼Œè€Œä¸æ˜¯å®é™…çš„æ¸©åº¦æ•°å€¼ã€‚æ¸©åº¦å¼‚å¸¸æœ‰åŠ©äºçªå‡ºé•¿æœŸçš„æ¸©åº¦å˜åŒ–è¶‹åŠ¿ã€‚å¯¹äºç ”ç©¶æ°”å€™å˜åŒ–è¿™æ ·çš„é•¿æœŸè¿‡ç¨‹ï¼Œå…³æ³¨æ¸©åº¦ç›¸å¯¹äºå†å²å¹³å‡å€¼çš„å˜åŒ–æ›´æœ‰æ„ä¹‰ã€‚å®ƒå¯ä»¥è¿‡æ»¤æ‰ä¸€äº›çŸ­æœŸçš„ã€å±€éƒ¨çš„æ¸©åº¦æ³¢åŠ¨ï¼Œè®©ç ”ç©¶äººå‘˜æ›´å‡†ç¡®åœ°æŠŠæ¡åœ°çƒæ°”å€™ç³»ç»Ÿæ˜¯åœ¨å˜æš–è¿˜æ˜¯å˜å†·è¿™æ ·çš„å®è§‚è¶‹åŠ¿ã€‚\n\n\n\ndf = df.set_index(\"Year\")\ndf.head()\ndf.tail()\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951â€”1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880â€”{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\né—®é¢˜ 2 è‡³ 4 (a)ä¸­çš„å›¾è¡¨å¯¹æ¸©åº¦å’Œæ—¶é—´ä¹‹é—´çš„å…³ç³»å¯ä»¥å‘ç°ï¼Œåœ¨1880å¹´åˆ°1930å¹´ä¹‹é—´ï¼Œæ¯å¹´ä¸€æœˆä»½çš„æ°”æ¸©ç›¸æ¯”äº1951-1980å¹´å¹³å‡æ°”æ¸©è¦ä½ï¼Œåç»­çš„å…³ç³»å‘ˆæ­£ç›¸å…³å…³ç³»ï¼Œå³éšç€æ—¶é—´çš„å¢é•¿æ°”æ¸©ä¹Ÿéšä¹‹å¢é•¿ã€‚\n\n\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951â€”1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880â€”{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921â€”1950\", \"1951â€”1980\", \"1981â€”2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();\n\n\n\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\n\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\n\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921â€”1950\", \"1951â€”1980\", \"1981â€”2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}â€”{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951â€”1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n\ndf_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\nä»ä¸Šè¿°å›¾æ ‡å¯ä»¥çœ‹å‡ºï¼Œå¹´ä»½ä¸CO_2çš„å…³ç³»å‘ˆæ­£ç›¸å…³å…³ç³»ï¼ŒåŒæ—¶ä¸šä½™æ°”æ¸©å˜åŒ–å‘ˆæ­£ç›¸å…³å…³ç³»ï¼Œè€Œä¸”ä»å®ƒä»¬çš„å˜åŒ–æ›²çº¿å¯ä»¥çœ‹å‡ºå‡å‘ˆæŒ‡æ•°å‹å¢é•¿ï¼Œå› æ­¤æ°”æ¸©å˜åŒ–å¼‚å¸¸ä¸äºŒæ°§åŒ–ç¢³æœ‰å…³ç³»ã€‚"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.1",
    "href": "lab.html#æ¼”ç»ƒ1.1",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\ndf.info()\næ¸©åº¦å¼‚å¸¸æ˜¯æŒ‡ç›¸å¯¹äºæŸä¸ªå‚è€ƒæ—¶æœŸçš„å¹³å‡æ¸©åº¦çš„åç¦»æƒ…å†µã€‚å®ƒæ˜¯ä¸€ç§è¡¡é‡å½“å‰æ¸©åº¦ä¸é•¿æœŸå¹³å‡æ¸©åº¦å·®å€¼çš„æ–¹å¼ï¼Œé‡ç‚¹åœ¨äºä½“ç°æ¸©åº¦çš„å˜åŒ–æƒ…å†µï¼Œè€Œä¸æ˜¯å®é™…çš„æ¸©åº¦æ•°å€¼ã€‚æ¸©åº¦å¼‚å¸¸æœ‰åŠ©äºçªå‡ºé•¿æœŸçš„æ¸©åº¦å˜åŒ–è¶‹åŠ¿ã€‚å¯¹äºç ”ç©¶æ°”å€™å˜åŒ–è¿™æ ·çš„é•¿æœŸè¿‡ç¨‹ï¼Œå…³æ³¨æ¸©åº¦ç›¸å¯¹äºå†å²å¹³å‡å€¼çš„å˜åŒ–æ›´æœ‰æ„ä¹‰ã€‚å®ƒå¯ä»¥è¿‡æ»¤æ‰ä¸€äº›çŸ­æœŸçš„ã€å±€éƒ¨çš„æ¸©åº¦æ³¢åŠ¨ï¼Œè®©ç ”ç©¶äººå‘˜æ›´å‡†ç¡®åœ°æŠŠæ¡åœ°çƒæ°”å€™ç³»ç»Ÿæ˜¯åœ¨å˜æš–è¿˜æ˜¯å˜å†·è¿™æ ·çš„å®è§‚è¶‹åŠ¿ã€‚"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.2",
    "href": "lab.html#æ¼”ç»ƒ1.2",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "df = df.set_index(\"Year\")\ndf.head()\ndf.tail()\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951â€”1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880â€”{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\né—®é¢˜ 2 è‡³ 4 (a)ä¸­çš„å›¾è¡¨å¯¹æ¸©åº¦å’Œæ—¶é—´ä¹‹é—´çš„å…³ç³»å¯ä»¥å‘ç°ï¼Œåœ¨1880å¹´åˆ°1930å¹´ä¹‹é—´ï¼Œæ¯å¹´ä¸€æœˆä»½çš„æ°”æ¸©ç›¸æ¯”äº1951-1980å¹´å¹³å‡æ°”æ¸©è¦ä½ï¼Œåç»­çš„å…³ç³»å‘ˆæ­£ç›¸å…³å…³ç³»ï¼Œå³éšç€æ—¶é—´çš„å¢é•¿æ°”æ¸©ä¹Ÿéšä¹‹å¢é•¿ã€‚"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.3",
    "href": "lab.html#æ¼”ç»ƒ1.3",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "month = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951â€”1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880â€”{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.4",
    "href": "lab.html#æ¼”ç»ƒ1.4",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "df[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921â€”1950\", \"1951â€”1980\", \"1981â€”2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.5",
    "href": "lab.html#æ¼”ç»ƒ1.5",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "temp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.6",
    "href": "lab.html#æ¼”ç»ƒ1.6",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.7",
    "href": "lab.html#æ¼”ç»ƒ1.7",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "temp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921â€”1950\", \"1951â€”1980\", \"1981â€”2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}â€”{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951â€”1980 average\", hjust=\"left\", color=\"black\"\n    )\n)"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ1.8",
    "href": "lab.html#æ¼”ç»ƒ1.8",
    "title": "å®éªŒå®¤",
    "section": "",
    "text": "df_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\nä»ä¸Šè¿°å›¾æ ‡å¯ä»¥çœ‹å‡ºï¼Œå¹´ä»½ä¸CO_2çš„å…³ç³»å‘ˆæ­£ç›¸å…³å…³ç³»ï¼ŒåŒæ—¶ä¸šä½™æ°”æ¸©å˜åŒ–å‘ˆæ­£ç›¸å…³å…³ç³»ï¼Œè€Œä¸”ä»å®ƒä»¬çš„å˜åŒ–æ›²çº¿å¯ä»¥çœ‹å‡ºå‡å‘ˆæŒ‡æ•°å‹å¢é•¿ï¼Œå› æ­¤æ°”æ¸©å˜åŒ–å¼‚å¸¸ä¸äºŒæ°§åŒ–ç¢³æœ‰å…³ç³»ã€‚"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.1",
    "href": "lab.html#æ¼”ç»ƒ2.1",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.1",
    "text": "æ¼”ç»ƒ2.1\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### â€” they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.2",
    "href": "lab.html#æ¼”ç»ƒ2.2",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.2",
    "text": "æ¼”ç»ƒ2.2\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\ndata_n.info()\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.3",
    "href": "lab.html#æ¼”ç»ƒ2.3",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.3",
    "text": "æ¼”ç»ƒ2.3\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.4",
    "href": "lab.html#æ¼”ç»ƒ2.4",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.4",
    "text": "æ¼”ç»ƒ2.4\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.5",
    "href": "lab.html#æ¼”ç»ƒ2.5",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.5",
    "text": "æ¼”ç»ƒ2.5\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"Â±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"Â±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.6",
    "href": "lab.html#æ¼”ç»ƒ2.6",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.6",
    "text": "æ¼”ç»ƒ2.6\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.7",
    "href": "lab.html#æ¼”ç»ƒ2.7",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.7",
    "text": "æ¼”ç»ƒ2.7\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n.loc[[1, 10], :].round(2)\nsumm_p.loc[[1, 10], :].round(2)"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ2.8",
    "href": "lab.html#æ¼”ç»ƒ2.8",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ2.8",
    "text": "æ¼”ç»ƒ2.8\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ3.1",
    "href": "lab.html#æ¼”ç»ƒ3.1",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ3.1",
    "text": "æ¼”ç»ƒ3.1\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\nimport requests\n\nurl = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n\n# Get the data from the ONS API:\njson_data = requests.get(url).json()\n\n# Prep the data for a quick plot\ntitle = json_data[\"description\"][\"title\"]\ndf = (\n    pd.DataFrame(pd.json_normalize(json_data[\"months\"]))\n    .assign(\n        date=lambda x: pd.to_datetime(x[\"date\"]),\n        value=lambda x: pd.to_numeric(x[\"value\"]),\n    )\n    .set_index(\"date\")\n)\n\ndf[\"value\"].plot(title=title, ylim=(0, df[\"value\"].max() * 1.2), lw=3.0);\nfrom pandas_datareader import wb\ndf = wb.download(\n    indicator=\"EN.ATM.CO2E.PC\",\n    country=[\"US\", \"CHN\", \"IND\", \"Z4\", \"Z7\"],\n    start=2017,\n    end=2017,\n)\n# remove country as index for ease of plotting with seaborn\ndf = df.reset_index()\n# wrap long country names\ndf[\"country\"] = df[\"country\"].apply(lambda x: textwrap.fill(x, 10))\n# order based on size\ndf = df.sort_values(\"EN.ATM.CO2E.PC\")\ndf.head()\nimport seaborn as sns\n\nfig, ax = plt.subplots()\nsns.barplot(x=\"country\", y=\"EN.ATM.CO2E.PC\", data=df.reset_index(), ax=ax)\nax.set_title(r\"CO$_2$ (metric tons per capita)\", loc=\"right\")\nplt.suptitle(\"The USA leads the world on per-capita emissions\", y=1.01)\nfor key, spine in ax.spines.items():\n    spine.set_visible(False)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\")\nax.yaxis.tick_right()\nplt.show()\nimport pandasdmx as pdmx\n# Tell pdmx we want OECD data\noecd = pdmx.Request(\"OECD\")\n# Set out everything about the request in the format specified by the OECD API\ndata = oecd.data(\n    resource_id=\"PDB_LV\",\n    key=\"GBR+FRA+CAN+ITA+DEU+JPN+USA.T_GDPEMP.CPC/all?startTime=2010\",\n).to_pandas()\n\ndf = pd.DataFrame(data).reset_index()\ndf.head()\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\nall_paras[1].text\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\nstart, stop = 0, 50\nroot_url = \"www.codingforeconomists.com/page=\"\ninfo_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\nimport pdftotext\nfrom pathlib import Path\n\n# Download the pdf_with_table.pdf file from\n# https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n# and put it in a subfolder called data before running the next line\n\n# Load the PDF\nwith open(Path(\"data/pdf_with_table.pdf\"), \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# Read all the text into one string; print a chunk of the string\nprint(\"\\n\\n\".join(pdf)[:220])\nimport camelot\n# Grab the pdf\ntables = camelot.read_pdf(os.path.join('data', 'pdf_with_table.pdf'))\nimport textract\ntext = textract.process(Path('path/to/file.extension'))"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ3.2",
    "href": "lab.html#æ¼”ç»ƒ3.2",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ3.2",
    "text": "æ¼”ç»ƒ3.2\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nheaders = {\n    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"\n}\nresponse = requests.get(url,headers=headers)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nmovies = soup.find_all('div',class_=\"sc-300a8231-0 gTnHyA cli-children\")\nratings = soup.find_all(\"span\",class_=\"ipc-rating-star--rating\")\nlist = []\n\nfor index in range(0, len(movies)):\n    \n    movie_string = movies[index].find(\"h3\",class_='ipc-title__text').get_text()\n    movie_title = movie_string.split(\".\")[1]\n    place = movie_string.split(\".\")[0]\n    year = movies[index].find(\"span\",class_='sc-300a8231-7 eaXxft cli-title-metadata-item').get_text()\n    \n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index].get_text(),\n            \"year\": year,\n            }\n    list.append(data)\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['rating'])\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)"
  },
  {
    "objectID": "lab.html#æ¼”ç»ƒ3.3",
    "href": "lab.html#æ¼”ç»ƒ3.3",
    "title": "å®éªŒå®¤",
    "section": "æ¼”ç»ƒ3.3",
    "text": "æ¼”ç»ƒ3.3\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\n# æå–ç”µå½±åç§°ã€æè¿°ã€è¯„åˆ†å’Œè¯„ä»·äººæ•°\nmovies = []\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\nfor page in range(10):\n    # å®šä¹‰è¯·æ±‚çš„ URL å’Œ headers\n    url = f\"https://movie.douban.com/top250?start={25 * page}&filter=\"\n    \n    # å‘é€ GET è¯·æ±‚\n    response = requests.get(url, headers=headers)\n    response.encoding = 'utf-8'  # è®¾ç½®ç¼–ç æ–¹å¼\n    html_content = response.text  # è·å–ç½‘é¡µçš„ HTML å†…å®¹\n    \n    # ä½¿ç”¨ Beautiful Soup è§£æ HTML\n    soup = BeautifulSoup(html_content, 'html.parser')\n    \n    \n    for item in soup.find_all('div', class_='item'):\n        title = item.find('span', class_='title').get_text()  # ç”µå½±åç§°\n        description = item.find('span', class_='inq')  # ç”µå½±æè¿°\n        rating = item.find('span', class_='rating_num').get_text()  # è¯„åˆ†\n        votes = item.find('div', class_='star').find_all('span')[3].get_text()  # è¯„ä»·äººæ•°\n        \n        # å¦‚æœæ²¡æœ‰æè¿°ï¼Œå°†å…¶ç½®ä¸ºç©ºå­—ç¬¦ä¸²\n        if description:\n            description = description.get_text()\n        else:\n            description = ''\n        \n        movie = {\n            \"title\": title,\n            \"description\": description,\n            \"rating\": rating,\n            \"votes\": votes.replace('äººè¯„ä»·', '').strip()\n        }\n        movies.append(movie)\n    break\n \n# å°†æ•°æ®ä¿å­˜åˆ° CSV æ–‡ä»¶\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # å†™å…¥è¡¨å¤´\n    for movie in movies:\n        writer.writerow(movie)  # å†™å…¥æ¯ä¸€è¡Œæ•°æ®\n \nprint(\"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° douban_top250.csv\")\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei']\n\n# è¯»å–CSVæ•°æ®\nfile_path = 'douban_top250.csv'  # ç¡®ä¿è·¯å¾„æ­£ç¡®\ndata = pd.read_csv(file_path)\n\n# æ ¹æ®è¯„åˆ†å±•ç¤ºTop 10ç”µå½±\ntop10_rating = data.nlargest(10, 'rating')  # å–è¯„åˆ†æœ€é«˜çš„å‰10éƒ¨ç”µå½±\n\nplt.figure(figsize=(10, 6))\nplt.barh(top10_rating['title'], top10_rating['rating'], color='skyblue')\nplt.xlabel('Rating')\nplt.title('Top 10 Movies by Rating')\nplt.gca().invert_yaxis()  # ç¿»è½¬Yè½´ï¼Œä½¿æ’åé å‰çš„ç”µå½±æ˜¾ç¤ºåœ¨é¡¶éƒ¨\nplt.show()\n# è¯„åˆ†ä¸æŠ•ç¥¨æ•°çš„æ•£ç‚¹å›¾\nplt.figure(figsize=(10, 6))\nplt.scatter(data['votes'], data['rating'], alpha=0.7, color='coral')\nplt.title('Relationship between Votes and Rating')\nplt.xlabel('Number of Votes')\nplt.ylabel('Rating')\nplt.grid(True)\nplt.show()"
  }
]