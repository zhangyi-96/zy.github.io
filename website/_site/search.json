[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "关于我",
    "section": "",
    "text": "欢迎来到我的网站！\n大家好！我是张颐，这是我用 Quarto 创建的个人学习网站。\n\n兴趣爱好:爱好打篮球，羽毛球，摄影 。\n目标:成为更优秀的人 。\n\n感谢您访问我的网站！😊"
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "实验室",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\ndf.info()\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。\n\n\n\ndf = df.set_index(\"Year\")\ndf.head()\ndf.tail()\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。\n\n\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();\n\n\n\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\n\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\n\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n\ndf_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。"
  },
  {
    "objectID": "lab.html#演练1.1",
    "href": "lab.html#演练1.1",
    "title": "实验室",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\ndf.info()\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。"
  },
  {
    "objectID": "lab.html#演练1.2",
    "href": "lab.html#演练1.2",
    "title": "实验室",
    "section": "",
    "text": "df = df.set_index(\"Year\")\ndf.head()\ndf.tail()\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。"
  },
  {
    "objectID": "lab.html#演练1.3",
    "href": "lab.html#演练1.3",
    "title": "实验室",
    "section": "",
    "text": "month = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");"
  },
  {
    "objectID": "lab.html#演练1.4",
    "href": "lab.html#演练1.4",
    "title": "实验室",
    "section": "",
    "text": "df[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();"
  },
  {
    "objectID": "lab.html#演练1.5",
    "href": "lab.html#演练1.5",
    "title": "实验室",
    "section": "",
    "text": "temp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")"
  },
  {
    "objectID": "lab.html#演练1.6",
    "href": "lab.html#演练1.6",
    "title": "实验室",
    "section": "",
    "text": "# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")"
  },
  {
    "objectID": "lab.html#演练1.7",
    "href": "lab.html#演练1.7",
    "title": "实验室",
    "section": "",
    "text": "temp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)"
  },
  {
    "objectID": "lab.html#演练1.8",
    "href": "lab.html#演练1.8",
    "title": "实验室",
    "section": "",
    "text": "df_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。"
  },
  {
    "objectID": "lab.html#演练2.1",
    "href": "lab.html#演练2.1",
    "title": "实验室",
    "section": "演练2.1",
    "text": "演练2.1\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### — they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");"
  },
  {
    "objectID": "lab.html#演练2.2",
    "href": "lab.html#演练2.2",
    "title": "实验室",
    "section": "演练2.2",
    "text": "演练2.2\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\ndata_n.info()\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")"
  },
  {
    "objectID": "lab.html#演练2.3",
    "href": "lab.html#演练2.3",
    "title": "实验室",
    "section": "演练2.3",
    "text": "演练2.3\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();"
  },
  {
    "objectID": "lab.html#演练2.4",
    "href": "lab.html#演练2.4",
    "title": "实验室",
    "section": "演练2.4",
    "text": "演练2.4\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);"
  },
  {
    "objectID": "lab.html#演练2.5",
    "href": "lab.html#演练2.5",
    "title": "实验室",
    "section": "演练2.5",
    "text": "演练2.5\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();"
  },
  {
    "objectID": "lab.html#演练2.6",
    "href": "lab.html#演练2.6",
    "title": "实验室",
    "section": "演练2.6",
    "text": "演练2.6\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();"
  },
  {
    "objectID": "lab.html#演练2.7",
    "href": "lab.html#演练2.7",
    "title": "实验室",
    "section": "演练2.7",
    "text": "演练2.7\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n.loc[[1, 10], :].round(2)\nsumm_p.loc[[1, 10], :].round(2)"
  },
  {
    "objectID": "lab.html#演练2.8",
    "href": "lab.html#演练2.8",
    "title": "实验室",
    "section": "演练2.8",
    "text": "演练2.8\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)"
  },
  {
    "objectID": "lab.html#演练3.1",
    "href": "lab.html#演练3.1",
    "title": "实验室",
    "section": "演练3.1",
    "text": "演练3.1\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\nimport requests\n\nurl = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n\n# Get the data from the ONS API:\njson_data = requests.get(url).json()\n\n# Prep the data for a quick plot\ntitle = json_data[\"description\"][\"title\"]\ndf = (\n    pd.DataFrame(pd.json_normalize(json_data[\"months\"]))\n    .assign(\n        date=lambda x: pd.to_datetime(x[\"date\"]),\n        value=lambda x: pd.to_numeric(x[\"value\"]),\n    )\n    .set_index(\"date\")\n)\n\ndf[\"value\"].plot(title=title, ylim=(0, df[\"value\"].max() * 1.2), lw=3.0);\nfrom pandas_datareader import wb\ndf = wb.download(\n    indicator=\"EN.ATM.CO2E.PC\",\n    country=[\"US\", \"CHN\", \"IND\", \"Z4\", \"Z7\"],\n    start=2017,\n    end=2017,\n)\n# remove country as index for ease of plotting with seaborn\ndf = df.reset_index()\n# wrap long country names\ndf[\"country\"] = df[\"country\"].apply(lambda x: textwrap.fill(x, 10))\n# order based on size\ndf = df.sort_values(\"EN.ATM.CO2E.PC\")\ndf.head()\nimport seaborn as sns\n\nfig, ax = plt.subplots()\nsns.barplot(x=\"country\", y=\"EN.ATM.CO2E.PC\", data=df.reset_index(), ax=ax)\nax.set_title(r\"CO$_2$ (metric tons per capita)\", loc=\"right\")\nplt.suptitle(\"The USA leads the world on per-capita emissions\", y=1.01)\nfor key, spine in ax.spines.items():\n    spine.set_visible(False)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\")\nax.yaxis.tick_right()\nplt.show()\nimport pandasdmx as pdmx\n# Tell pdmx we want OECD data\noecd = pdmx.Request(\"OECD\")\n# Set out everything about the request in the format specified by the OECD API\ndata = oecd.data(\n    resource_id=\"PDB_LV\",\n    key=\"GBR+FRA+CAN+ITA+DEU+JPN+USA.T_GDPEMP.CPC/all?startTime=2010\",\n).to_pandas()\n\ndf = pd.DataFrame(data).reset_index()\ndf.head()\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\nall_paras[1].text\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\nstart, stop = 0, 50\nroot_url = \"www.codingforeconomists.com/page=\"\ninfo_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\nimport pdftotext\nfrom pathlib import Path\n\n# Download the pdf_with_table.pdf file from\n# https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n# and put it in a subfolder called data before running the next line\n\n# Load the PDF\nwith open(Path(\"data/pdf_with_table.pdf\"), \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# Read all the text into one string; print a chunk of the string\nprint(\"\\n\\n\".join(pdf)[:220])\nimport camelot\n# Grab the pdf\ntables = camelot.read_pdf(os.path.join('data', 'pdf_with_table.pdf'))\nimport textract\ntext = textract.process(Path('path/to/file.extension'))"
  },
  {
    "objectID": "lab.html#演练3.2",
    "href": "lab.html#演练3.2",
    "title": "实验室",
    "section": "演练3.2",
    "text": "演练3.2\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nheaders = {\n    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"\n}\nresponse = requests.get(url,headers=headers)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nmovies = soup.find_all('div',class_=\"sc-300a8231-0 gTnHyA cli-children\")\nratings = soup.find_all(\"span\",class_=\"ipc-rating-star--rating\")\nlist = []\n\nfor index in range(0, len(movies)):\n    \n    movie_string = movies[index].find(\"h3\",class_='ipc-title__text').get_text()\n    movie_title = movie_string.split(\".\")[1]\n    place = movie_string.split(\".\")[0]\n    year = movies[index].find(\"span\",class_='sc-300a8231-7 eaXxft cli-title-metadata-item').get_text()\n    \n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index].get_text(),\n            \"year\": year,\n            }\n    list.append(data)\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['rating'])\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)"
  },
  {
    "objectID": "lab.html#演练3.3",
    "href": "lab.html#演练3.3",
    "title": "实验室",
    "section": "演练3.3",
    "text": "演练3.3\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\n# 提取电影名称、描述、评分和评价人数\nmovies = []\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\nfor page in range(10):\n    # 定义请求的 URL 和 headers\n    url = f\"https://movie.douban.com/top250?start={25 * page}&filter=\"\n    \n    # 发送 GET 请求\n    response = requests.get(url, headers=headers)\n    response.encoding = 'utf-8'  # 设置编码方式\n    html_content = response.text  # 获取网页的 HTML 内容\n    \n    # 使用 Beautiful Soup 解析 HTML\n    soup = BeautifulSoup(html_content, 'html.parser')\n    \n    \n    for item in soup.find_all('div', class_='item'):\n        title = item.find('span', class_='title').get_text()  # 电影名称\n        description = item.find('span', class_='inq')  # 电影描述\n        rating = item.find('span', class_='rating_num').get_text()  # 评分\n        votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n        \n        # 如果没有描述，将其置为空字符串\n        if description:\n            description = description.get_text()\n        else:\n            description = ''\n        \n        movie = {\n            \"title\": title,\n            \"description\": description,\n            \"rating\": rating,\n            \"votes\": votes.replace('人评价', '').strip()\n        }\n        movies.append(movie)\n    break\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei']\n\n# 读取CSV数据\nfile_path = 'douban_top250.csv'  # 确保路径正确\ndata = pd.read_csv(file_path)\n\n# 根据评分展示Top 10电影\ntop10_rating = data.nlargest(10, 'rating')  # 取评分最高的前10部电影\n\nplt.figure(figsize=(10, 6))\nplt.barh(top10_rating['title'], top10_rating['rating'], color='skyblue')\nplt.xlabel('Rating')\nplt.title('Top 10 Movies by Rating')\nplt.gca().invert_yaxis()  # 翻转Y轴，使排名靠前的电影显示在顶部\nplt.show()\n# 评分与投票数的散点图\nplt.figure(figsize=(10, 6))\nplt.scatter(data['votes'], data['rating'], alpha=0.7, color='coral')\nplt.title('Relationship between Votes and Rating')\nplt.xlabel('Number of Votes')\nplt.ylabel('Rating')\nplt.grid(True)\nplt.show()"
  }
]